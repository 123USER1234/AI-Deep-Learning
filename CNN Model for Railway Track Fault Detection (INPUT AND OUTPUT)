from google.colab import drive
drive.mount('/content/drive', force_remount=True)

Mounted at /content/drive

train_dir = '/content/drive/MyDrive/train'  
test_dir = '/content/drive/MyDrive/test'    

import os
print(len(os.listdir('/content/drive/MyDrive/train/Defective')))
print(len(os.listdir('/content/drive/MyDrive/train/Non defective')))
print(len(os.listdir('/content/drive/MyDrive/test/Defective')))
print(len(os.listdir('/content/drive/MyDrive/test/Non defective')))

150
150
11
11

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# The following creates ImageDataGenerator for the training set
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2  # divides and splits 20% of the images for validation set
)

# Next, load the training data and prepare it for processing
train_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=(256,256),
    batch_size=32,
    class_mode='binary',  # specifying 'binary' as it is a binary classification (defective vs. non-defective)
    subset='training'  # selecting 'training' fot the training dataset
)

# Second part is to create ImageDataGenerator for the validation dataset
validation_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2  # Note: Using the same validation split as in the training set
)

# import and prepare the validation dataset for processing
validation_data = validation_datagen.flow_from_directory(
    train_dir,
    target_size=(256,256),
    batch_size=32,
    class_mode='binary',
    subset='validation'  # specifying 'validation' for the validation dataset
)

Found 240 images belonging to 2 classes.
Found 59 images belonging to 2 classes.

from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,UpSampling2D, Dropout

# Now to create the Convolution Neural Network CNN Model

model = Sequential()

model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))  # 32 filters
#model.add(BatchNormalization())  # in order to reduce overfitting
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))
#model.add(BatchNormalization())  # in order to reduce overfitting
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
#model.add(BatchNormalization())  # in order to reduce overfitting
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Flatten())

model.add(Dense(128,activation='relu')) #feature reduction
#model.add(Dropout(0.1))  # in order to reduce overfitting
model.add(Dense(64,activation='relu'))
#model.add(Dropout(0.1))  # in order to reduce overfitting
model.add(Dense(1,activation='sigmoid'))  #output layer

from keras.optimizers import Adam
model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy']) #binary_crossentropy - binary classification

history = model.fit(train_data, epochs=30, validation_data=validation_data)

Epoch 1/30
8/8 [==============================] - 41s 5s/step - loss: 1.6670e-05 - accuracy: 1.0000 - val_loss: 2.7680 - val_accuracy: 0.5593
Epoch 2/30
8/8 [==============================] - 39s 5s/step - loss: 1.6329e-05 - accuracy: 1.0000 - val_loss: 2.7734 - val_accuracy: 0.5593
Epoch 3/30
8/8 [==============================] - 49s 6s/step - loss: 1.5956e-05 - accuracy: 1.0000 - val_loss: 2.7788 - val_accuracy: 0.5593
Epoch 4/30
8/8 [==============================] - 41s 5s/step - loss: 1.5564e-05 - accuracy: 1.0000 - val_loss: 2.7849 - val_accuracy: 0.5593
Epoch 5/30
8/8 [==============================] - 41s 5s/step - loss: 1.5288e-05 - accuracy: 1.0000 - val_loss: 2.7905 - val_accuracy: 0.5593
Epoch 6/30
8/8 [==============================] - 42s 5s/step - loss: 1.4867e-05 - accuracy: 1.0000 - val_loss: 2.7969 - val_accuracy: 0.5593
Epoch 7/30
8/8 [==============================] - 39s 5s/step - loss: 1.4532e-05 - accuracy: 1.0000 - val_loss: 2.8031 - val_accuracy: 0.5593
Epoch 8/30
8/8 [==============================] - 42s 5s/step - loss: 1.4153e-05 - accuracy: 1.0000 - val_loss: 2.8084 - val_accuracy: 0.5593
Epoch 9/30
8/8 [==============================] - 39s 5s/step - loss: 1.3920e-05 - accuracy: 1.0000 - val_loss: 2.8154 - val_accuracy: 0.5593
Epoch 10/30
8/8 [==============================] - 42s 5s/step - loss: 1.3557e-05 - accuracy: 1.0000 - val_loss: 2.8207 - val_accuracy: 0.5593
Epoch 11/30
8/8 [==============================] - 39s 5s/step - loss: 1.3258e-05 - accuracy: 1.0000 - val_loss: 2.8250 - val_accuracy: 0.5593
Epoch 12/30
8/8 [==============================] - 39s 5s/step - loss: 1.3031e-05 - accuracy: 1.0000 - val_loss: 2.8295 - val_accuracy: 0.5593
Epoch 13/30
8/8 [==============================] - 40s 5s/step - loss: 1.2698e-05 - accuracy: 1.0000 - val_loss: 2.8345 - val_accuracy: 0.5593
Epoch 14/30
8/8 [==============================] - 39s 5s/step - loss: 1.2457e-05 - accuracy: 1.0000 - val_loss: 2.8389 - val_accuracy: 0.5593
Epoch 15/30
8/8 [==============================] - 40s 5s/step - loss: 1.2189e-05 - accuracy: 1.0000 - val_loss: 2.8443 - val_accuracy: 0.5593
Epoch 16/30
8/8 [==============================] - 39s 5s/step - loss: 1.1913e-05 - accuracy: 1.0000 - val_loss: 2.8488 - val_accuracy: 0.5593
Epoch 17/30
8/8 [==============================] - 41s 5s/step - loss: 1.1651e-05 - accuracy: 1.0000 - val_loss: 2.8528 - val_accuracy: 0.5593
Epoch 18/30
8/8 [==============================] - 39s 5s/step - loss: 1.1454e-05 - accuracy: 1.0000 - val_loss: 2.8577 - val_accuracy: 0.5593
Epoch 19/30
8/8 [==============================] - 43s 5s/step - loss: 1.1249e-05 - accuracy: 1.0000 - val_loss: 2.8629 - val_accuracy: 0.5593
Epoch 20/30
8/8 [==============================] - 46s 6s/step - loss: 1.0975e-05 - accuracy: 1.0000 - val_loss: 2.8682 - val_accuracy: 0.5593
Epoch 21/30
8/8 [==============================] - 42s 5s/step - loss: 1.0755e-05 - accuracy: 1.0000 - val_loss: 2.8721 - val_accuracy: 0.5593
Epoch 22/30
8/8 [==============================] - 46s 6s/step - loss: 1.0527e-05 - accuracy: 1.0000 - val_loss: 2.8771 - val_accuracy: 0.5593
Epoch 23/30
8/8 [==============================] - 46s 6s/step - loss: 1.0333e-05 - accuracy: 1.0000 - val_loss: 2.8806 - val_accuracy: 0.5593
Epoch 24/30
8/8 [==============================] - 44s 6s/step - loss: 1.0110e-05 - accuracy: 1.0000 - val_loss: 2.8856 - val_accuracy: 0.5593
Epoch 25/30
8/8 [==============================] - 45s 6s/step - loss: 9.9238e-06 - accuracy: 1.0000 - val_loss: 2.8899 - val_accuracy: 0.5593
Epoch 26/30
8/8 [==============================] - 43s 5s/step - loss: 9.7089e-06 - accuracy: 1.0000 - val_loss: 2.8949 - val_accuracy: 0.5593
Epoch 27/30
8/8 [==============================] - 39s 5s/step - loss: 9.5432e-06 - accuracy: 1.0000 - val_loss: 2.9002 - val_accuracy: 0.5593
Epoch 28/30
8/8 [==============================] - 42s 5s/step - loss: 9.3615e-06 - accuracy: 1.0000 - val_loss: 2.9049 - val_accuracy: 0.5593
Epoch 29/30
8/8 [==============================] - 39s 5s/step - loss: 9.1868e-06 - accuracy: 1.0000 - val_loss: 2.9087 - val_accuracy: 0.5593
Epoch 30/30
8/8 [==============================] - 42s 6s/step - loss: 9.0421e-06 - accuracy: 1.0000 - val_loss: 2.9113 - val_accuracy: 0.5593

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'],color='red',label='train')
plt.plot(history.history['val_accuracy'],color='blue',label='validation')
plt.legend()
plt.show()

(line chart 1 output)

plt.plot(history.history['loss'],color='red',label='train')
plt.plot(history.history['val_loss'],color='blue',label='validation')
plt.legend()
plt.show()

(line chart 2 output)

test_datagen = ImageDataGenerator(rescale=1./255)
test_data = test_datagen.flow_from_directory(
    test_dir,
    target_size=(256,256),
    batch_size=32,
    class_mode='binary'
)

Found 22 images belonging to 2 classes.

#predict the test data
predictions = model.predict(test_data)
print(predictions)

1/1 [==============================] - 1s 1s/step
[[7.9456049e-06]
 [6.3022082e-07]
 [9.9798042e-01]
 [9.9182540e-01]
 [6.1857048e-03]
 [3.5379675e-01]
 [1.1356722e-03]
 [1.9005445e-07]
 [1.0000000e+00]
 [4.7759765e-01]
 [9.9916732e-01]
 [9.6350014e-01]
 [1.2368691e-08]
 [9.7958803e-01]
 [6.2124485e-19]
 [9.9544507e-01]
 [3.1216867e-13]
 [9.9959350e-01]
 [2.4623240e-08]
 [9.9999928e-01]
 [4.7738394e-14]
 [8.0804932e-01]]

len(predictions)
22

from sklearn.metrics import confusion_matrix, classification_report

# Assuming you have ground truth labels (true_labels) and predicted labels (predictions)
true_labels = test_data.classes
predicted_labels = (predictions > 0.5).astype(int)  # Adjust the threshold as needed

# Calculate confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Print confusion matrix
print("Confusion Matrix:")
print(cm)

# Print classification report
print("Classification Report:")
print(classification_report(true_labels, predicted_labels))

Confusion Matrix:
[[7 4]
 [5 6]]
Classification Report:
              precision    recall  f1-score   support

           0       0.58      0.64      0.61        11
           1       0.60      0.55      0.57        11

    accuracy                           0.59        22
   macro avg       0.59      0.59      0.59        22
weighted avg       0.59      0.59      0.59        22

